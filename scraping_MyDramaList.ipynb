{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOAL : Scrape Drama Reviews\n",
    "FROM: https://mydramalist.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_place = 'C:/Users/Hanna Kim/Documents/데잇걸즈 4기/공공데이터 공모전/chromedriver'\n",
    "\n",
    "#고정된 driver page열어주기\n",
    "driver = webdriver.Chrome(driver_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(soup):\n",
    "    title = []\n",
    "    reviewer = []\n",
    "    # create list for each column\n",
    "    story = []\n",
    "    acting = []\n",
    "    music = []\n",
    "    rewatch = []\n",
    "    tire = soup.select(\"a.text-primary\")\n",
    "    score = soup.select(\"span.p-l-md.pull-right\")\n",
    "    for i in range(int(len(tire)/3)):\n",
    "        title.append(tire[3*i].text)\n",
    "        reviewer.append(tire[3*i+1].text)\n",
    "        story.append(score[4*i].text) \n",
    "        acting.append(score[4*i+1].text)\n",
    "        music.append(score[4*i+2].text)\n",
    "        rewatch.append(score[4*i+3].text)\n",
    "    overall = [*map(lambda x:x.text,soup.select(\"span.score\"))]\n",
    "    \n",
    "    return pd.DataFrame({\"title\":title, \"reviewer\":reviewer, \"overall\":overall,\"story\":story,\"acting\":acting, \"music\":music, \"rewatch\":rewatch})\n",
    "\n",
    "\n",
    "def drama_users(drama):\n",
    "    '''\n",
    "    get top 12 reviewers in drama\n",
    "    \n",
    "    try with example:\n",
    "        18452-goblin\n",
    "        18894-strong-woman-do-bong-soon\n",
    "    \n",
    "    drama_users(\"drama tag for link\")\n",
    "    '''\n",
    "    url = f\"https://mydramalist.com/{drama}/reviews\"\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    prof = []\n",
    "    for i in soup.select(\"a.text-primary\"):\n",
    "        prof.append(i.get(\"href\"))\n",
    "    profile_list = [x[9:] for x in prof if x.startswith(\"/profile\") & ~x.endswith(\"/reviews\")][4:]\n",
    "    return profile_list\n",
    "\n",
    "\n",
    "def check_exist_class():\n",
    "    '''\n",
    "    #when exists\n",
    "    url = 'https://mydramalist.com/profile/dragynfaerie/reviews'\n",
    "    driver.get(url)\n",
    "    check_exist_class()\n",
    "\n",
    "    #when not\n",
    "    url = 'https://mydramalist.com/profile/Chacha35/reviews'\n",
    "    driver.get(url)\n",
    "    check_exist_class()\n",
    "    '''\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"page-item.nb.active\")\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최종 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this has reviews\n",
      "this has reviews\n",
      "this has reviews\n",
      "this has reviews\n",
      "this has reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# profile_list = ['BounamaHoussam', 'dragynfaerie','Tanya94','Chacha35']\n",
    "# 테스트용 프로필 리스트 원래는 drama_users로 구해야함\n",
    "\n",
    "\n",
    "profile_list = drama_users('18452-goblin')\n",
    "many_users = pd.DataFrame({\"title\":[], \"reviewer\":[], \"overall\":[],\"story\":[],\"acting\":[], \"music\":[], \"rewatch\":[]})\n",
    "\n",
    "for user_id in profile_list:\n",
    "    \n",
    "    url = f'https://mydramalist.com/profile/{user_id}/reviews'\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    time.sleep(10)\n",
    "    # review 없는 경우 제외\n",
    "    if soup.select(\"div.box-body\")[-1].text != \"There have been no reviews submitted.\":\n",
    "        print(\"this has reviews\")\n",
    "        \n",
    "        #첫번째 페이지 긁어서 프레임 만들기\n",
    "        page_num = 1\n",
    "        pages_frame = get_frame(soup)\n",
    "        \n",
    "        # 리뷰가 12개 미만이면 더 구할게 없음\n",
    "        if check_exist_class():\n",
    "            while soup.select_one(\"li.page-item.nb.active\").text == str(page_num):\n",
    "                if soup.select_one(\"li.page-item.nb.active\").text != str(page_num): \n",
    "                    break\n",
    "                page_num += 1\n",
    "                page_url = url + f'?page={page_num}'\n",
    "                driver.get(page_url)\n",
    "                html = driver.page_source\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                time.sleep(10)\n",
    "                imsi =get_frame(soup)\n",
    "                pages_frame = pd.concat([pages_frame, imsi])\n",
    "            many_users = pd.concat([many_users, pages_frame])\n",
    "        else:\n",
    "            many_users = pd.concat([many_users, pages_frame])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>overall</th>\n",
       "      <th>story</th>\n",
       "      <th>acting</th>\n",
       "      <th>music</th>\n",
       "      <th>rewatch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Sunshine</td>\n",
       "      <td>kingsqueen</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goblin</td>\n",
       "      <td>kingsqueen</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Bride of Habaek</td>\n",
       "      <td>kingsqueen</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jealousy Incarnate</td>\n",
       "      <td>kingsqueen</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suspicious Partner</td>\n",
       "      <td>kingsqueen</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One More Time</td>\n",
       "      <td>Ivana</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Village: Achiara's Secret</td>\n",
       "      <td>Ivana</td>\n",
       "      <td>9.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Guardians</td>\n",
       "      <td>Ivana</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W</td>\n",
       "      <td>VandaLimbata</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Goblin</td>\n",
       "      <td>VandaLimbata</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title      reviewer overall story acting music  \\\n",
       "0                    Mr. Sunshine    kingsqueen      10    10     10    10   \n",
       "1                          Goblin    kingsqueen      10    10     10    10   \n",
       "2             The Bride of Habaek    kingsqueen     7.0   7.0    7.0   9.0   \n",
       "3              Jealousy Incarnate    kingsqueen     8.5   8.5     10    10   \n",
       "4              Suspicious Partner    kingsqueen     7.0   7.0    9.0   7.0   \n",
       "..                            ...           ...     ...   ...    ...   ...   \n",
       "3                   One More Time         Ivana     7.5   5.5    7.5   9.5   \n",
       "4   The Village: Achiara's Secret         Ivana     9.5   9.0     10    10   \n",
       "5                   The Guardians         Ivana      10    10     10    10   \n",
       "0                               W  VandaLimbata     5.5   5.0    6.5   9.0   \n",
       "1                          Goblin  VandaLimbata     6.5   6.5    9.0    10   \n",
       "\n",
       "   rewatch  \n",
       "0       10  \n",
       "1       10  \n",
       "2      5.5  \n",
       "3      9.0  \n",
       "4      5.0  \n",
       "..     ...  \n",
       "3      7.5  \n",
       "4      7.5  \n",
       "5       10  \n",
       "0      1.0  \n",
       "1      3.5  \n",
       "\n",
       "[665 rows x 7 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kingsqueen75',\n",
       " 'dragynfaerie',\n",
       " 'Ghettoe',\n",
       " 'Tanya94',\n",
       " 'wonhwa',\n",
       " 'Mrmz',\n",
       " 'sambart',\n",
       " 'Chacha35',\n",
       " 'Nathansgurl',\n",
       " 'Karoline00',\n",
       " 'Ive',\n",
       " 'VandaLimbata']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top drama links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://mydramalist.com/shows/popular\")\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/18452-goblin',\n",
       " '/18894-strong-woman-do-bong-soon',\n",
       " '/2987-boys-over-flowers',\n",
       " '/10904-descendants-of-the-sun',\n",
       " '/7398-you-who-came-from-the-stars',\n",
       " '/6640-the-heirs',\n",
       " '/16589-w',\n",
       " '/19262-weightlifting-fairy-kim-bok-joo',\n",
       " '/11074-pinocchio',\n",
       " '/10814-healer',\n",
       " '/8-secret-garden-2010',\n",
       " '/21576-while-you-were-sleeping',\n",
       " '/27885-why-secretary-kim',\n",
       " '/2986-youre-beautiful',\n",
       " '/15999-moon-lovers-scarlet-heart-ryeo',\n",
       " '/10873-kill-me-heal-me',\n",
       " '/2982-coffee-prince',\n",
       " '/1702-city-hunter-2011',\n",
       " '/6993-i-hear-your-voice',\n",
       " '/18816-the-legend-of-the-blue-sea']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noli = [x.get(\"href\") for x in soup.select('h6.text-primary.title>a')]\n",
    "famous_drama = [i for i in noli if i]\n",
    "famous_drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BounamaHoussam',\n",
       " 'hideyourheart',\n",
       " 'Hessa',\n",
       " 'hyungyshik',\n",
       " 'kingsqueen75',\n",
       " 'pinkspades',\n",
       " 'manicmuse',\n",
       " 'Thevilone',\n",
       " 'Tsukkitori',\n",
       " 'lovecoutureflyy',\n",
       " 'Wererabbit',\n",
       " '_Rosie',\n",
       " 'HermanFassett',\n",
       " 'vale383',\n",
       " 'binja-man697',\n",
       " 'MichaelTang']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-db3774ebb6ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_one_user_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprofile_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_imsi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_one_user_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_imsi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-108-f15033b2be50>\u001b[0m in \u001b[0;36mget_one_user_frame\u001b[1;34m(userid)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"li.page-item.nb.active\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"li.page-item.nb.active\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "data = get_one_user_frame(profile_list[0])\n",
    "for i in profile_list[1:3]:\n",
    "    data_imsi = get_one_user_frame(i)\n",
    "    data = pd.concat([data,data_imsi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "soup = get_pg(1)\n",
    "a =1\n",
    "while soup.select_one(\"li.page-item.nb.active\").text == str(a):\n",
    "    print(\"same\")\n",
    "    if soup.select_one(\"li.page-item.nb.active\").text != str(a):\n",
    "        print(\"not same\")\n",
    "        break\n",
    "    a +=1\n",
    "    soup = get_pg(a)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
